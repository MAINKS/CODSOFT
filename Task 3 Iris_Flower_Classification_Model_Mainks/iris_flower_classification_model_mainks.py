# -*- coding: utf-8 -*-
"""Iris Flower Classification Model Mainks.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1DKYMwIiuIFwxxtz32HHm_kVc49sa1TyZ

#Iris Flower Classification

##Import Necessary Libraries
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import classification_report, confusion_matrix
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier

"""## Load the Dataset"""

#Load the Dataset

df = pd.read_csv('IRIS.csv')

"""#Data Exploration and Preprocessing"""

print(df.head())
print(df.info())
print(df.describe())

"""##Check for Missing Values"""

print(df.isnull().sum())

"""#Data Visualization"""

#Visualize the relationships between different features using pair plots and histograms to understand the distribution of data.
sns.pairplot(df, hue='species')
plt.show()
df.hist(edgecolor='black', figsize=(10, 8))
plt.show()

"""#Label Encoding"""

from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()
df['species'] = le.fit_transform(df['species'])

"""#Train & Test Set splitting

##Feature Selection: Select the features (sepal length, sepal width, petal length, petal width) and the target variable (species).
"""

#Select the features (sepal length, sepal width, petal length, petal width) and the target variable (species).
X = df.drop(columns=['species'])
y = df['species']

"""#Split the Data"""

#Split the Data into Training and Testing Sets: Split the data into 80% training and 20% testing.
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

"""#Feature Scaling"""

#Standardize the Features: It’s crucial to standardize the features so that they have a mean of 0 and a standard deviation of 1.
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

"""#Model Building

##KNN Model
"""

#Choose and Train a Model: Start by training multiple models like K-Nearest Neighbors (KNN), Decision Tree, and Random Forest.

knn = KNeighborsClassifier(n_neighbors=5)
knn.fit(X_train, y_train)

"""##Decision Tree Model"""

dtree = DecisionTreeClassifier()
dtree.fit(X_train, y_train)

"""##Random Forest Model"""

rf = RandomForestClassifier(n_estimators=100)
rf.fit(X_train, y_train)

"""#Model Evaluation

##KNN Evaluation
"""

#Evaluate the Models: Use accuracy, confusion matrix, and classification report to evaluate each model’s performance.
y_pred_knn = knn.predict(X_test)
print(confusion_matrix(y_test, y_pred_knn))
print(classification_report(y_test, y_pred_knn))

"""##Decision Tree Evaluation"""

y_pred_dtree = dtree.predict(X_test)
print(confusion_matrix(y_test, y_pred_dtree))
print(classification_report(y_test, y_pred_dtree))

"""##Random Forest Evaluation"""

y_pred_rf = rf.predict(X_test)
print(confusion_matrix(y_test, y_pred_rf))
print(classification_report(y_test, y_pred_rf))

"""##Save the Model"""

#Saving the best model for future use using joblib or pickle.
import joblib
joblib.dump(rf, 'iris_rf_model.pkl')